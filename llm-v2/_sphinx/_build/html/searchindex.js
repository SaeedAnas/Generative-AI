Search.setIndex({"docnames": ["demo", "elastic-search-notes", "es-setup-nb", "index", "modules", "svlearn", "svlearn.common", "svlearn.compute", "svlearn.config", "svlearn.service.rest.fastapi", "svlearn.service.rest.rayserve", "svlearn.sql", "svlearn.text", "text-extraction-nb"], "filenames": ["demo.ipynb", "elastic-search-notes.ipynb", "es-setup-nb.rst", "index.rst", "modules.rst", "svlearn.rst", "svlearn.common.rst", "svlearn.compute.rst", "svlearn.config.rst", "svlearn.service.rest.fastapi.rst", "svlearn.service.rest.rayserve.rst", "svlearn.sql.rst", "svlearn.text.rst", "text-extraction-nb.rst"], "titles": ["import required modules.", "ElasticSearch installation notes", "Elastic-Setup Demo", "Welcome to LLM-Bootcamp\u2019s documentation!", "svlearn", "svlearn package", "svlearn.common package", "svlearn.compute package", "svlearn.config package", "svlearn.service.rest.fastapi package", "svlearn.service.rest.rayserve package", "svlearn.sql package", "svlearn.text package", "Text-Extraction Demo"], "terms": {"11": [0, 1], "from": [0, 1, 7, 8, 9, 12], "svlearn": 0, "text": [0, 2, 4, 5, 7, 9], "text_extractor": [0, 3, 4, 5], "textextract": [0, 5, 12], "textractor": 0, "12": [0, 1], "valid_sample_sent": 0, "txt": 0, "13": 0, "data": 0, "raw_text": 0, "text_": 0, "34": 0, "thi": [0, 7, 9, 10, 12], "i": [0, 6, 7, 9, 10, 12], "first": 0, "r": 0, "nhere": 0, "39": [0, 1], "": [0, 1], "second": 0, "one": [0, 12], "nthe": 0, "third": 0, "goe": 0, "here": 0, "nsentenc": 0, "number": [0, 1, 12], "four": 0, "nand": 0, "final": [0, 1], "fifth": 0, "conclud": 0, "chunked_text": 0, "sent": [0, 7], "sentences_": 0, "lt": [0, 1], "gener": [0, 1], "0x27940f36cc0": 0, "gt": [0, 1], "doc_typ": 0, "doctype_": 0, "plain": [0, 7, 12], "doc_languag": 0, "language_": 0, "en": 0, "To": [1, 3, 13], "download": 1, "linix": 1, "wget": 1, "http": 1, "artifact": 1, "elast": [1, 12], "co": 1, "8": 1, "9": 1, "2": 1, "linux": 1, "x86_64": 1, "tar": 1, "gz": 1, "next": 1, "uncompress": 1, "archiv": 1, "file": [1, 3, 6, 7, 8, 12, 13], "xzf": 1, "Then": 1, "set": [1, 7, 12], "up": 1, "es_hom": 1, "environ": 1, "variabl": 1, "directori": [1, 6, 7], "enter": 1, "bin": 1, "start": 1, "server": [1, 9, 10], "command": 1, "In": 1, "output": [1, 7], "log": 1, "down": 1, "password": 1, "store": [1, 6, 7], "elastic_password": 1, "pip": 1, "collect": 1, "0": 1, "py3": 1, "none": [1, 6, 7, 8, 10, 12], "ani": 1, "whl": 1, "395": 1, "kb": 1, "5": 1, "4": 1, "mb": 1, "eta": 1, "00": 1, "transport": 1, "elastic_transport": 1, "59": 1, "requir": [1, 3, 6, 13], "alreadi": 1, "satisfi": 1, "certifi": 1, "c": 1, "user": 1, "l_cha": 1, "anaconda3": 1, "lib": 1, "site": 1, "packag": [1, 3, 4], "2022": 1, "7": 1, "urllib3": 1, "1": [1, 12], "26": 1, "14": 1, "successfulli": 1, "import": [1, 3, 13], "o": 1, "getenv": 1, "instanc": [1, 7, 8], "localhost": 1, "9200": 1, "ca_cert": 1, "config": [1, 3, 4, 5], "cert": 1, "http_ca": 1, "crt": 1, "basic_auth": 1, "success": 1, "respons": 1, "info": 1, "name": [1, 6, 10, 12], "0000000000": 1, "cluster_nam": 1, "objectapirespons": 1, "snow": 1, "mountain": 1, "cluster_uuid": 1, "5_uh2scbtn6uswclp5zkwg": 1, "version": [1, 10], "build_flavor": 1, "default": 1, "build_typ": 1, "build_hash": 1, "e8179018838f55b8820685f92e245abef3bddc0f": 1, "build_dat": 1, "2023": 1, "08": 1, "31t02": 1, "43": 1, "210479707z": 1, "build_snapshot": 1, "fals": [1, 6], "lucene_vers": 1, "minimum_wire_compatibility_vers": 1, "17": 1, "minimum_index_compatibility_vers": 1, "taglin": 1, "you": [1, 9], "know": 1, "3": 1, "datetim": 1, "doc": 1, "author": 1, "author_nam": 1, "interest": 1, "content": [1, 4], "timestamp": 1, "now": 1, "resp": 1, "test": [1, 9], "id": [1, 12], "print": 1, "result": [1, 12], "_sourc": 1, "09": 1, "15t20": 1, "789704": 1, "indic": 1, "_shard": 1, "total": 1, "fail": 1, "6": 1, "modifi": 1, "tika": [1, 12], "parser": 1, "path": [1, 6, 8, 12], "home": 1, "asif": 1, "parsed_doc": 1, "listdir": 1, "8888": 1, "notebook": 1, "ipynb": 1, "isfil": 1, "join": 1, "file_with_path": 1, "append": 1, "from_fil": 1, "qamar": 1, "10": 1, "queri": [1, 12], "got": 1, "d": 1, "hit": 1, "valu": 1, "506734": 1, "16": [1, 12], "294440": 1, "support": [1, 10, 12], "vector": [1, 5, 7, 9, 12], "elasticsearch": [2, 3, 7], "instal": [2, 3], "note": [2, 3], "python": [2, 3], "e": [2, 3, 7], "sampl": [2, 3], "code": [2, 3], "creat": [2, 3, 7, 12], "client": [2, 3], "an": [2, 3, 7, 8, 12], "index": [2, 3, 7, 12], "ad": [2, 3], "document": [2, 7, 12, 13], "get": [2, 3, 13], "refresh": [2, 3], "updat": [2, 3, 7], "anoth": [2, 3, 7], "same": [2, 3], "search": [2, 3, 5, 12], "all": [2, 3, 7], "give": [2, 3], "match_al": [2, 3], "match": [2, 3], "some": [2, 3, 9, 10, 12], "kei": [2, 3, 8], "word": [2, 3], "subpackag": [3, 4], "common": [3, 4, 5], "submodul": [3, 4, 5], "nnio": [3, 4, 5], "modul": [3, 4, 13], "sv_type": [3, 4, 5], "svexcept": [3, 4, 5], "util": [3, 4, 5], "comput": [3, 4, 5, 12], "ann_indexer_job": [3, 4, 5], "bootcamp_compute_job": [3, 4, 5], "chunk_vector": [3, 4, 5], "chunker_job": [3, 4, 5], "compute_util": [3, 4, 5], "es_indexer_job": [3, 4, 5], "text_extraction_job": [3, 4, 5], "configur": [3, 4, 5], "sql": [3, 4, 5], "connect": [3, 4, 5, 7], "es_index_search": [3, 4, 5], "faiss_index": [3, 4, 5], "indexer_poc": [3, 4, 5], "query_results_rerank": [3, 4, 5], "sentence_encod": [3, 4, 5], "text_chunk": [3, 4, 5], "servic": [3, 4, 5, 7], "rest": [3, 4, 5, 7], "rayserv": [3, 4, 5], "clean_chunk_servic": [3, 4, 5], "sentence_embedding_servic": [3, 4, 5], "faiss_index_builder_servic": [3, 4, 5], "faiss_search_servic": [3, 4, 5], "search_servic": [3, 4, 5], "query_results_reranking_servic": [3, 4, 5], "fastapi": [3, 4, 5], "clean_chunk_fastapi_servic": [3, 4, 5], "faiss_fastapi_index_builder_servic": [3, 4, 5], "sentence_embedding_fastapi_servic": [3, 4, 5], "provid": [3, 9, 10, 12, 13], "filepath": [3, 13], "raw": [3, 13], "input": [3, 7, 13], "chunk": [3, 5, 7, 9, 12, 13], "sentenc": [3, 5, 7, 9, 12, 13], "type": [3, 6, 12, 13], "languag": [3, 13], "page": 3, "load_model": [5, 6], "save_model": [5, 6], "missingargumenterror": [5, 6], "sverror": [5, 6, 12], "unspecifieddirectoryerror": [5, 6], "unspecifiedfileerror": [5, 6], "delete_fil": [5, 6], "directory_exist": [5, 6], "directory_is_empti": [5, 6], "directory_read": [5, 6], "directory_writ": [5, 6], "ensure_directori": [5, 6], "file_exist": [5, 6], "file_is_empti": [5, 6], "file_read": [5, 6], "file_writ": [5, 6], "annindexerjob": [5, 7], "describ": [5, 7], "run": [5, 7, 11], "call_faiss_indexer_endpoint": [5, 7], "index_per_partit": [5, 7], "bootcampcomputejob": [5, 7], "chunkvectorizerjob": [5, 7], "call_embedding_endpoint": [5, 7], "persist_vector": [5, 7], "textchunkerjob": [5, 7], "call_chunker_endpoint": [5, 7], "persist_chunk": [5, 7], "esindexerjob": [5, 7], "call_rest_partit": [5, 7], "textextractionjob": [5, 7], "configurationmixin": [5, 7, 8, 9, 10, 12], "load_config": [5, 8], "elasticsearchindex": [5, 12], "faissindex": [5, 12], "add": [5, 12], "create_brute_force_index": [5, 12], "create_hnsw_index": [5, 12], "create_ivf_index": [5, 12], "load_index": [5, 12], "save_index": [5, 9, 12], "size": [5, 12], "queryresultsrerank": [5, 12], "rerank": [5, 12], "sentenceencod": [5, 12], "encod": [5, 9, 12], "chunktext": [5, 12], "cosine_similar": [5, 12], "create_chunk": [5, 12], "create_list_of_chunk": [5, 12], "document_typ": [5, 12], "to_text": [5, 12], "textextractionerror": [5, 12], "cleanchunkmodel": [5, 9, 10], "sentenceencodermodel": [5, 9, 10], "faissindexbuilderservic": [5, 9, 10], "faisssearchservic": [5, 10], "hybridsearch": [5, 10], "queryresultsrerankermodel": [5, 10], "initialize_chunk": [5, 9], "inputrequest": [5, 9], "initialize_index": [5, 9], "vectorrequest": [5, 9], "add_to_index": [5, 9], "initialize_embedd": [5, 9], "embed": [5, 7, 9], "file_path": 6, "str": [6, 7, 9, 12], "dict": 6, "sourc": [6, 7, 8, 9, 10, 11, 12], "save": [6, 12], "model": [6, 9, 10, 12], "system": 6, "param": [6, 7, 8, 12], "state_dict": 6, "full": 6, "return": [6, 7, 8, 12], "state": 6, "dictionari": 6, "except": [6, 12], "arg": 6, "base": [6, 7, 8, 9, 10, 12], "messag": [6, 12], "rais": [6, 12], "when": [6, 12], "specifi": 6, "paramet": [6, 12], "argument": 6, "should": [6, 9], "contain": [6, 12], "explan": [6, 12], "error": [6, 12], "object": [6, 8, 9, 12], "file_nam": 6, "check": 6, "given": [6, 7, 12], "exist": [6, 12], "filesystem": [6, 12], "delet": 6, "doe": [6, 7], "string": [6, 12], "dir_nam": 6, "bool": 6, "true": [6, 7], "otherwis": 6, "its": [6, 7], "ar": [6, 7], "readabl": 6, "empti": 6, "writabl": 6, "class": [7, 8, 9, 10, 12], "entri": [7, 9], "point": [7, 9, 12], "ann": 7, "job": 7, "tabl": 7, "un": 7, "send": 7, "method": [7, 12], "where": [7, 12], "retriev": 7, "also": 7, "ann_index": 7, "column": 7, "row": 7, "end": 7, "ann_index_url": 7, "input_vector": 7, "list": [7, 9, 12], "tupl": [7, 9, 12], "int": [7, 9, 12], "float": [7, 9, 12], "call": 7, "endpoint": 7, "take": [7, 12], "post": 7, "request": [7, 9], "url": 7, "record": 7, "each": [7, 12], "partit": 7, "incom": 7, "datafram": 7, "repres": 7, "job_nam": 7, "config_fil": [7, 8], "abc": 7, "py": 7, "spark": 7, "abstract": 7, "It": 7, "cla": 7, "implement": 7, "them": 7, "persist": 7, "db": 7, "back": 7, "sentence_vectorizer_url": 7, "text_input": 7, "A": 7, "associ": 7, "databas": 7, "chunker": 7, "unchunk": 7, "clean_chunk_url": 7, "clean": [7, 9, 12], "es_index": 7, "For": 7, "follow": 7, "extract": [7, 12], "read": 7, "subdirectori": 7, "recurs": 7, "commentedmap": 8, "load": [8, 9, 10, 12], "yaml": 8, "rtype": 8, "map": 8, "like": 8, "preserv": 8, "order": 8, "basemodel": 9, "async": 9, "simpl": 9, "bootcamp": [9, 10], "exercis": [9, 10], "recal": [9, 10], "our": 9, "discuss": 9, "prefer": 9, "rai": [9, 10], "serv": [9, 10], "pytorch": 9, "tensorflow": 9, "etc": [9, 10, 12], "product": 9, "thei": 9, "have": 9, "ai": [9, 10], "specif": [9, 10], "featur": [9, 10], "built": [9, 10], "toward": [9, 10], "concurr": [9, 10], "control": [9, 10], "balanc": [9, 10], "howev": [9, 12], "sometim": 9, "mai": 9, "want": 9, "quickli": 9, "out": 9, "your": 9, "idea": 9, "quick": 9, "rout": 9, "dure": 9, "develop": 9, "process": 9, "few": 9, "can": [9, 12], "us": [9, 12], "alia": 10, "deploy": 10, "route_prefix": 10, "query_str": 12, "score": 12, "index_fil": 12, "index_typ": 12, "brute_forc": 12, "dimens": 12, "64": 12, "metric_typ": 12, "nlist": 12, "100": 12, "vector_list": 12, "brute": 12, "forc": 12, "bewar": 12, "veri": 12, "slow": 12, "larg": 12, "dataset": 12, "m": 12, "efconstruct": 12, "40": 12, "hnsw": 12, "much": 12, "faster": 12, "than": 12, "accur": 12, "neighbor": 12, "explor": 12, "construct": 12, "time": 12, "ivf": 12, "need": 12, "train": 12, "befor": 12, "metric": 12, "distanc": 12, "between": 12, "cell": 12, "quantiz": 12, "function": 12, "smaller": 12, "piec": 12, "after": 12, "cleanup": 12, "The": 12, "includ": 12, "remov": 12, "newlin": 12, "tab": 12, "extra": 12, "space": 12, "within": 12, "re": 12, "rank": 12, "revers": 12, "sort": 12, "determin": 12, "tensor": 12, "ndarrai": 12, "static": 12, "\u03b1": 12, "\u03b2": 12, "bit": 12, "text_list": 12, "mime": 12, "applic": 12, "pdf": 12, "format": 12, "could": 12, "which": 12}, "objects": {"": [[5, 0, 0, "-", "svlearn"]], "svlearn": [[6, 0, 0, "-", "common"], [7, 0, 0, "-", "compute"], [8, 0, 0, "-", "config"], [11, 0, 0, "-", "sql"], [12, 0, 0, "-", "text"]], "svlearn.common": [[6, 0, 0, "-", "nnio"], [6, 0, 0, "-", "sv_types"], [6, 0, 0, "-", "svexception"], [6, 0, 0, "-", "utils"]], "svlearn.common.nnio": [[6, 1, 1, "", "load_model"], [6, 1, 1, "", "save_model"]], "svlearn.common.svexception": [[6, 2, 1, "", "MissingArgumentError"], [6, 2, 1, "", "SVError"], [6, 2, 1, "", "UnspecifiedDirectoryError"], [6, 2, 1, "", "UnspecifiedFileError"]], "svlearn.common.utils": [[6, 1, 1, "", "delete_file"], [6, 1, 1, "", "directory_exists"], [6, 1, 1, "", "directory_is_empty"], [6, 1, 1, "", "directory_readable"], [6, 1, 1, "", "directory_writable"], [6, 1, 1, "", "ensure_directory"], [6, 1, 1, "", "file_exists"], [6, 1, 1, "", "file_is_empty"], [6, 1, 1, "", "file_readable"], [6, 1, 1, "", "file_writable"]], "svlearn.compute": [[7, 0, 0, "-", "ann_indexer_job"], [7, 0, 0, "-", "bootcamp_compute_job"], [7, 0, 0, "-", "chunk_vectorizer"], [7, 0, 0, "-", "chunker_job"], [7, 0, 0, "-", "compute_utils"], [7, 0, 0, "-", "es_indexer_job"], [7, 0, 0, "-", "text_extraction_job"]], "svlearn.compute.ann_indexer_job": [[7, 3, 1, "", "ANNIndexerJob"], [7, 1, 1, "", "call_faiss_indexer_endpoint"], [7, 1, 1, "", "index_per_partition"]], "svlearn.compute.ann_indexer_job.ANNIndexerJob": [[7, 4, 1, "", "describe"], [7, 4, 1, "", "run"]], "svlearn.compute.bootcamp_compute_job": [[7, 3, 1, "", "BootcampComputeJob"]], "svlearn.compute.bootcamp_compute_job.BootcampComputeJob": [[7, 4, 1, "", "describe"], [7, 4, 1, "", "run"]], "svlearn.compute.chunk_vectorizer": [[7, 3, 1, "", "ChunkVectorizerJob"], [7, 1, 1, "", "call_embedding_endpoint"], [7, 1, 1, "", "persist_vectors"]], "svlearn.compute.chunk_vectorizer.ChunkVectorizerJob": [[7, 4, 1, "", "describe"], [7, 4, 1, "", "run"]], "svlearn.compute.chunker_job": [[7, 3, 1, "", "TextChunkerJob"], [7, 1, 1, "", "call_chunker_endpoint"], [7, 1, 1, "", "persist_chunks"]], "svlearn.compute.chunker_job.TextChunkerJob": [[7, 4, 1, "", "describe"], [7, 4, 1, "", "run"]], "svlearn.compute.es_indexer_job": [[7, 3, 1, "", "ESIndexerJob"], [7, 1, 1, "", "call_rest_partition"]], "svlearn.compute.es_indexer_job.ESIndexerJob": [[7, 4, 1, "", "describe"], [7, 4, 1, "", "run"]], "svlearn.compute.text_extraction_job": [[7, 3, 1, "", "TextExtractionJob"]], "svlearn.compute.text_extraction_job.TextExtractionJob": [[7, 4, 1, "", "describe"], [7, 4, 1, "", "run"]], "svlearn.config": [[8, 0, 0, "-", "configuration"]], "svlearn.config.configuration": [[8, 3, 1, "", "ConfigurationMixin"]], "svlearn.config.configuration.ConfigurationMixin": [[8, 4, 1, "", "load_config"]], "svlearn.service.rest": [[9, 0, 0, "-", "fastapi"], [10, 0, 0, "-", "rayserve"]], "svlearn.service.rest.fastapi": [[9, 0, 0, "-", "clean_chunk_fastapi_service"], [9, 0, 0, "-", "faiss_fastapi_index_builder_service"], [9, 0, 0, "-", "sentence_embedding_fastapi_service"]], "svlearn.service.rest.fastapi.clean_chunk_fastapi_service": [[9, 3, 1, "", "CleanChunkModel"], [9, 3, 1, "", "InputRequest"], [9, 1, 1, "", "chunk"]], "svlearn.service.rest.fastapi.clean_chunk_fastapi_service.CleanChunkModel": [[9, 4, 1, "", "initialize_chunker"]], "svlearn.service.rest.fastapi.clean_chunk_fastapi_service.InputRequest": [[9, 5, 1, "", "text"]], "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service": [[9, 3, 1, "", "FaissIndexBuilderService"], [9, 3, 1, "", "VectorRequest"], [9, 1, 1, "", "add_to_index"]], "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.FaissIndexBuilderService": [[9, 4, 1, "", "initialize_index"], [9, 4, 1, "", "save_index"]], "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.VectorRequest": [[9, 5, 1, "", "vectors"]], "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service": [[9, 3, 1, "", "InputRequest"], [9, 3, 1, "", "SentenceEncoderModel"], [9, 1, 1, "", "embedding"]], "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.InputRequest": [[9, 5, 1, "", "sentences"]], "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.SentenceEncoderModel": [[9, 4, 1, "", "initialize_embedder"]], "svlearn.service.rest.rayserve": [[10, 0, 0, "-", "clean_chunk_service"], [10, 0, 0, "-", "faiss_index_builder_service"], [10, 0, 0, "-", "faiss_search_service"], [10, 0, 0, "-", "query_results_reranking_service"], [10, 0, 0, "-", "search_service"], [10, 0, 0, "-", "sentence_embedding_service"]], "svlearn.service.rest.rayserve.clean_chunk_service": [[10, 5, 1, "", "CleanChunkModel"]], "svlearn.service.rest.rayserve.faiss_index_builder_service": [[10, 5, 1, "", "FaissIndexBuilderService"]], "svlearn.service.rest.rayserve.faiss_search_service": [[10, 5, 1, "", "FaissSearchService"]], "svlearn.service.rest.rayserve.query_results_reranking_service": [[10, 5, 1, "", "QueryResultsReRankerModel"]], "svlearn.service.rest.rayserve.search_service": [[10, 3, 1, "", "HybridSearch"]], "svlearn.service.rest.rayserve.sentence_embedding_service": [[10, 5, 1, "", "SentenceEncoderModel"]], "svlearn.sql": [[11, 0, 0, "-", "connect"]], "svlearn.sql.connect": [[11, 1, 1, "", "run"]], "svlearn.text": [[12, 0, 0, "-", "es_index_searcher"], [12, 0, 0, "-", "faiss_indexer"], [12, 0, 0, "-", "indexer_poc"], [12, 0, 0, "-", "query_results_reranker"], [12, 0, 0, "-", "sentence_encoder"], [12, 0, 0, "-", "text_chunker"], [12, 0, 0, "-", "text_extractor"]], "svlearn.text.es_index_searcher": [[12, 3, 1, "", "ElasticSearchIndex"]], "svlearn.text.es_index_searcher.ElasticSearchIndex": [[12, 4, 1, "", "search"]], "svlearn.text.faiss_indexer": [[12, 3, 1, "", "FaissIndexer"]], "svlearn.text.faiss_indexer.FaissIndexer": [[12, 4, 1, "", "add"], [12, 4, 1, "", "create_brute_force_index"], [12, 4, 1, "", "create_hnsw_index"], [12, 4, 1, "", "create_ivf_index"], [12, 4, 1, "", "load_index"], [12, 4, 1, "", "save_index"], [12, 4, 1, "", "size"]], "svlearn.text.query_results_reranker": [[12, 3, 1, "", "QueryResultsReRanker"]], "svlearn.text.query_results_reranker.QueryResultsReRanker": [[12, 4, 1, "", "rerank"]], "svlearn.text.sentence_encoder": [[12, 3, 1, "", "SentenceEncoder"]], "svlearn.text.sentence_encoder.SentenceEncoder": [[12, 4, 1, "", "encode"]], "svlearn.text.text_chunker": [[12, 3, 1, "", "ChunkText"]], "svlearn.text.text_chunker.ChunkText": [[12, 4, 1, "", "cosine_similarity"], [12, 4, 1, "", "create_chunks"], [12, 4, 1, "", "create_list_of_chunks"]], "svlearn.text.text_extractor": [[12, 3, 1, "", "TextExtraction"], [12, 2, 1, "", "TextExtractionError"]], "svlearn.text.text_extractor.TextExtraction": [[12, 4, 1, "", "document_type"], [12, 4, 1, "", "to_text"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:exception", "3": "py:class", "4": "py:method", "5": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "exception", "Python exception"], "3": ["py", "class", "Python class"], "4": ["py", "method", "Python method"], "5": ["py", "attribute", "Python attribute"]}, "titleterms": {"import": 0, "requir": 0, "modul": [0, 5, 6, 7, 8, 9, 10, 11, 12], "provid": 0, "filepath": 0, "To": 0, "get": [0, 1], "raw": 0, "content": [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13], "input": 0, "file": 0, "chunk": 0, "sentenc": 0, "type": 0, "languag": 0, "document": [0, 1, 3], "elasticsearch": 1, "instal": 1, "note": 1, "python": 1, "e": 1, "sampl": 1, "code": 1, "creat": 1, "client": 1, "an": 1, "index": 1, "ad": 1, "refresh": 1, "updat": 1, "anoth": 1, "same": 1, "search": 1, "all": 1, "give": 1, "match_al": 1, "match": 1, "some": 1, "kei": 1, "word": 1, "text": [1, 3, 12, 13], "elast": [2, 3], "setup": [2, 3], "demo": [2, 3, 13], "welcom": 3, "llm": 3, "bootcamp": 3, "": 3, "svlearn": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "extract": [3, 13], "indic": 3, "tabl": 3, "packag": [5, 6, 7, 8, 9, 10, 11, 12], "subpackag": 5, "common": 6, "submodul": [6, 7, 8, 9, 10, 11, 12], "nnio": 6, "sv_type": 6, "svexcept": 6, "util": 6, "comput": 7, "ann_indexer_job": 7, "bootcamp_compute_job": 7, "chunk_vector": 7, "chunker_job": 7, "compute_util": 7, "es_indexer_job": 7, "text_extraction_job": 7, "config": 8, "configur": 8, "servic": [9, 10], "rest": [9, 10], "fastapi": 9, "clean_chunk_fastapi_servic": 9, "faiss_fastapi_index_builder_servic": 9, "sentence_embedding_fastapi_servic": 9, "rayserv": 10, "clean_chunk_servic": 10, "sentence_embedding_servic": 10, "faiss_index_builder_servic": 10, "faiss_search_servic": 10, "search_servic": 10, "query_results_reranking_servic": 10, "sql": 11, "connect": 11, "es_index_search": 12, "faiss_index": 12, "indexer_poc": 12, "query_results_rerank": 12, "sentence_encod": 12, "text_chunk": 12, "text_extractor": 12}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"import required modules.": [[0, "import-required-modules."]], "provide filepath": [[0, "provide-filepath"]], "To get raw-content of input file": [[0, "To-get-raw-content-of-input-file"]], "To get chunked sentences": [[0, "To-get-chunked-sentences"]], "To get input-file type": [[0, "To-get-input-file-type"]], "To get language of input-document content.": [[0, "To-get-language-of-input-document-content."]], "ElasticSearch installation notes": [[1, "ElasticSearch-installation-notes"]], "Python ES installation": [[1, "Python-ES-installation"]], "Sample python code": [[1, "Sample-python-code"]], "Creating ES client": [[1, "Creating-ES-client"]], "Creating an index and adding a document": [[1, "Creating-an-index-and-adding-a-document"]], "Getting a document": [[1, "Getting-a-document"]], "Refreshing an index": [[1, "Refreshing-an-index"]], "Updating a document": [[1, "Updating-a-document"]], "Adding another document to same index": [[1, "Adding-another-document-to-same-index"]], "Searching for all documents in the index by giving a match_all": [[1, "Searching-for-all-documents-in-the-index-by-giving-a-match_all"]], "Searching for all documents matching some key words in the text": [[1, "Searching-for-all-documents-matching-some-key-words-in-the-text"]], "Elastic-Setup Demo": [[2, "elastic-setup-demo"], [3, "elastic-setup-demo"]], "Content:": [[2, null], [3, null]], "Welcome to LLM-Bootcamp\u2019s documentation!": [[3, "welcome-to-llm-bootcamp-s-documentation"]], "svlearn": [[3, "svlearn"], [4, "svlearn"]], "Text-Extraction Demo": [[3, "text-extraction-demo"], [13, "text-extraction-demo"]], "Contents:": [[3, null], [13, null]], "Indices and tables": [[3, "indices-and-tables"]], "svlearn package": [[5, "svlearn-package"]], "Subpackages": [[5, "subpackages"]], "Module contents": [[5, "module-svlearn"], [6, "module-svlearn.common"], [7, "module-svlearn.compute"], [8, "module-svlearn.config"], [9, "module-svlearn.service.rest.fastapi"], [10, "module-svlearn.service.rest.rayserve"], [11, "module-svlearn.sql"], [12, "module-svlearn.text"]], "svlearn.common package": [[6, "svlearn-common-package"]], "Submodules": [[6, "submodules"], [7, "submodules"], [8, "submodules"], [9, "submodules"], [10, "submodules"], [11, "submodules"], [12, "submodules"]], "svlearn.common.nnio module": [[6, "module-svlearn.common.nnio"]], "svlearn.common.sv_types module": [[6, "module-svlearn.common.sv_types"]], "svlearn.common.svexception module": [[6, "module-svlearn.common.svexception"]], "svlearn.common.utils module": [[6, "module-svlearn.common.utils"]], "svlearn.compute package": [[7, "svlearn-compute-package"]], "svlearn.compute.ann_indexer_job module": [[7, "module-svlearn.compute.ann_indexer_job"]], "svlearn.compute.bootcamp_compute_job module": [[7, "module-svlearn.compute.bootcamp_compute_job"]], "svlearn.compute.chunk_vectorizer module": [[7, "module-svlearn.compute.chunk_vectorizer"]], "svlearn.compute.chunker_job module": [[7, "module-svlearn.compute.chunker_job"]], "svlearn.compute.compute_utils module": [[7, "module-svlearn.compute.compute_utils"]], "svlearn.compute.es_indexer_job module": [[7, "module-svlearn.compute.es_indexer_job"]], "svlearn.compute.text_extraction_job module": [[7, "module-svlearn.compute.text_extraction_job"]], "svlearn.config package": [[8, "svlearn-config-package"]], "svlearn.config.configuration module": [[8, "module-svlearn.config.configuration"]], "svlearn.service.rest.fastapi package": [[9, "svlearn-service-rest-fastapi-package"]], "svlearn.service.rest.fastapi.clean_chunk_fastapi_service module": [[9, "module-svlearn.service.rest.fastapi.clean_chunk_fastapi_service"]], "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service module": [[9, "module-svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service"]], "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service module": [[9, "module-svlearn.service.rest.fastapi.sentence_embedding_fastapi_service"]], "svlearn.service.rest.rayserve package": [[10, "svlearn-service-rest-rayserve-package"]], "svlearn.service.rest.rayserve.clean_chunk_service module": [[10, "module-svlearn.service.rest.rayserve.clean_chunk_service"]], "svlearn.service.rest.rayserve.sentence_embedding_service module": [[10, "module-svlearn.service.rest.rayserve.sentence_embedding_service"]], "svlearn.service.rest.rayserve.faiss_index_builder_service module": [[10, "module-svlearn.service.rest.rayserve.faiss_index_builder_service"]], "svlearn.service.rest.rayserve.faiss_search_service module": [[10, "module-svlearn.service.rest.rayserve.faiss_search_service"]], "svlearn.service.rest.rayserve.search_service module": [[10, "module-svlearn.service.rest.rayserve.search_service"]], "svlearn.service.rest.rayserve.query_results_reranking_service module": [[10, "module-svlearn.service.rest.rayserve.query_results_reranking_service"]], "svlearn.sql package": [[11, "svlearn-sql-package"]], "svlearn.sql.connect module": [[11, "module-svlearn.sql.connect"]], "svlearn.text package": [[12, "svlearn-text-package"]], "svlearn.text.es_index_searcher module": [[12, "module-svlearn.text.es_index_searcher"]], "svlearn.text.faiss_indexer module": [[12, "module-svlearn.text.faiss_indexer"]], "svlearn.text.indexer_poc module": [[12, "module-svlearn.text.indexer_poc"]], "svlearn.text.query_results_reranker module": [[12, "module-svlearn.text.query_results_reranker"]], "svlearn.text.sentence_encoder module": [[12, "module-svlearn.text.sentence_encoder"]], "svlearn.text.text_chunker module": [[12, "module-svlearn.text.text_chunker"]], "svlearn.text.text_extractor module": [[12, "module-svlearn.text.text_extractor"]]}, "indexentries": {"module": [[5, "module-svlearn"], [6, "module-svlearn.common"], [6, "module-svlearn.common.nnio"], [6, "module-svlearn.common.sv_types"], [6, "module-svlearn.common.svexception"], [6, "module-svlearn.common.utils"], [7, "module-svlearn.compute"], [7, "module-svlearn.compute.ann_indexer_job"], [7, "module-svlearn.compute.bootcamp_compute_job"], [7, "module-svlearn.compute.chunk_vectorizer"], [7, "module-svlearn.compute.chunker_job"], [7, "module-svlearn.compute.compute_utils"], [7, "module-svlearn.compute.es_indexer_job"], [7, "module-svlearn.compute.text_extraction_job"], [8, "module-svlearn.config"], [8, "module-svlearn.config.configuration"], [9, "module-svlearn.service.rest.fastapi"], [9, "module-svlearn.service.rest.fastapi.clean_chunk_fastapi_service"], [9, "module-svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service"], [9, "module-svlearn.service.rest.fastapi.sentence_embedding_fastapi_service"], [10, "module-svlearn.service.rest.rayserve"], [10, "module-svlearn.service.rest.rayserve.clean_chunk_service"], [10, "module-svlearn.service.rest.rayserve.faiss_index_builder_service"], [10, "module-svlearn.service.rest.rayserve.faiss_search_service"], [10, "module-svlearn.service.rest.rayserve.query_results_reranking_service"], [10, "module-svlearn.service.rest.rayserve.search_service"], [10, "module-svlearn.service.rest.rayserve.sentence_embedding_service"], [11, "module-svlearn.sql"], [11, "module-svlearn.sql.connect"], [12, "module-svlearn.text"], [12, "module-svlearn.text.es_index_searcher"], [12, "module-svlearn.text.faiss_indexer"], [12, "module-svlearn.text.indexer_poc"], [12, "module-svlearn.text.query_results_reranker"], [12, "module-svlearn.text.sentence_encoder"], [12, "module-svlearn.text.text_chunker"], [12, "module-svlearn.text.text_extractor"]], "svlearn": [[5, "module-svlearn"]], "missingargumenterror": [[6, "svlearn.common.svexception.MissingArgumentError"]], "sverror": [[6, "svlearn.common.svexception.SVError"]], "unspecifieddirectoryerror": [[6, "svlearn.common.svexception.UnspecifiedDirectoryError"]], "unspecifiedfileerror": [[6, "svlearn.common.svexception.UnspecifiedFileError"]], "delete_file() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.delete_file"]], "directory_exists() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.directory_exists"]], "directory_is_empty() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.directory_is_empty"]], "directory_readable() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.directory_readable"]], "directory_writable() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.directory_writable"]], "ensure_directory() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.ensure_directory"]], "file_exists() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.file_exists"]], "file_is_empty() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.file_is_empty"]], "file_readable() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.file_readable"]], "file_writable() (in module svlearn.common.utils)": [[6, "svlearn.common.utils.file_writable"]], "load_model() (in module svlearn.common.nnio)": [[6, "svlearn.common.nnio.load_model"]], "save_model() (in module svlearn.common.nnio)": [[6, "svlearn.common.nnio.save_model"]], "svlearn.common": [[6, "module-svlearn.common"]], "svlearn.common.nnio": [[6, "module-svlearn.common.nnio"]], "svlearn.common.sv_types": [[6, "module-svlearn.common.sv_types"]], "svlearn.common.svexception": [[6, "module-svlearn.common.svexception"]], "svlearn.common.utils": [[6, "module-svlearn.common.utils"]], "annindexerjob (class in svlearn.compute.ann_indexer_job)": [[7, "svlearn.compute.ann_indexer_job.ANNIndexerJob"]], "bootcampcomputejob (class in svlearn.compute.bootcamp_compute_job)": [[7, "svlearn.compute.bootcamp_compute_job.BootcampComputeJob"]], "chunkvectorizerjob (class in svlearn.compute.chunk_vectorizer)": [[7, "svlearn.compute.chunk_vectorizer.ChunkVectorizerJob"]], "esindexerjob (class in svlearn.compute.es_indexer_job)": [[7, "svlearn.compute.es_indexer_job.ESIndexerJob"]], "textchunkerjob (class in svlearn.compute.chunker_job)": [[7, "svlearn.compute.chunker_job.TextChunkerJob"]], "textextractionjob (class in svlearn.compute.text_extraction_job)": [[7, "svlearn.compute.text_extraction_job.TextExtractionJob"]], "call_chunker_endpoint() (in module svlearn.compute.chunker_job)": [[7, "svlearn.compute.chunker_job.call_chunker_endpoint"]], "call_embedding_endpoint() (in module svlearn.compute.chunk_vectorizer)": [[7, "svlearn.compute.chunk_vectorizer.call_embedding_endpoint"]], "call_faiss_indexer_endpoint() (in module svlearn.compute.ann_indexer_job)": [[7, "svlearn.compute.ann_indexer_job.call_faiss_indexer_endpoint"]], "call_rest_partition() (in module svlearn.compute.es_indexer_job)": [[7, "svlearn.compute.es_indexer_job.call_rest_partition"]], "describe() (svlearn.compute.ann_indexer_job.annindexerjob method)": [[7, "svlearn.compute.ann_indexer_job.ANNIndexerJob.describe"]], "describe() (svlearn.compute.bootcamp_compute_job.bootcampcomputejob method)": [[7, "svlearn.compute.bootcamp_compute_job.BootcampComputeJob.describe"]], "describe() (svlearn.compute.chunk_vectorizer.chunkvectorizerjob method)": [[7, "svlearn.compute.chunk_vectorizer.ChunkVectorizerJob.describe"]], "describe() (svlearn.compute.chunker_job.textchunkerjob method)": [[7, "svlearn.compute.chunker_job.TextChunkerJob.describe"]], "describe() (svlearn.compute.es_indexer_job.esindexerjob method)": [[7, "svlearn.compute.es_indexer_job.ESIndexerJob.describe"]], "describe() (svlearn.compute.text_extraction_job.textextractionjob method)": [[7, "svlearn.compute.text_extraction_job.TextExtractionJob.describe"]], "index_per_partition() (in module svlearn.compute.ann_indexer_job)": [[7, "svlearn.compute.ann_indexer_job.index_per_partition"]], "persist_chunks() (in module svlearn.compute.chunker_job)": [[7, "svlearn.compute.chunker_job.persist_chunks"]], "persist_vectors() (in module svlearn.compute.chunk_vectorizer)": [[7, "svlearn.compute.chunk_vectorizer.persist_vectors"]], "run() (svlearn.compute.ann_indexer_job.annindexerjob method)": [[7, "svlearn.compute.ann_indexer_job.ANNIndexerJob.run"]], "run() (svlearn.compute.bootcamp_compute_job.bootcampcomputejob method)": [[7, "svlearn.compute.bootcamp_compute_job.BootcampComputeJob.run"]], "run() (svlearn.compute.chunk_vectorizer.chunkvectorizerjob method)": [[7, "svlearn.compute.chunk_vectorizer.ChunkVectorizerJob.run"]], "run() (svlearn.compute.chunker_job.textchunkerjob method)": [[7, "svlearn.compute.chunker_job.TextChunkerJob.run"]], "run() (svlearn.compute.es_indexer_job.esindexerjob method)": [[7, "svlearn.compute.es_indexer_job.ESIndexerJob.run"]], "run() (svlearn.compute.text_extraction_job.textextractionjob method)": [[7, "svlearn.compute.text_extraction_job.TextExtractionJob.run"]], "svlearn.compute": [[7, "module-svlearn.compute"]], "svlearn.compute.ann_indexer_job": [[7, "module-svlearn.compute.ann_indexer_job"]], "svlearn.compute.bootcamp_compute_job": [[7, "module-svlearn.compute.bootcamp_compute_job"]], "svlearn.compute.chunk_vectorizer": [[7, "module-svlearn.compute.chunk_vectorizer"]], "svlearn.compute.chunker_job": [[7, "module-svlearn.compute.chunker_job"]], "svlearn.compute.compute_utils": [[7, "module-svlearn.compute.compute_utils"]], "svlearn.compute.es_indexer_job": [[7, "module-svlearn.compute.es_indexer_job"]], "svlearn.compute.text_extraction_job": [[7, "module-svlearn.compute.text_extraction_job"]], "configurationmixin (class in svlearn.config.configuration)": [[8, "svlearn.config.configuration.ConfigurationMixin"]], "load_config() (svlearn.config.configuration.configurationmixin method)": [[8, "svlearn.config.configuration.ConfigurationMixin.load_config"]], "svlearn.config": [[8, "module-svlearn.config"]], "svlearn.config.configuration": [[8, "module-svlearn.config.configuration"]], "cleanchunkmodel (class in svlearn.service.rest.fastapi.clean_chunk_fastapi_service)": [[9, "svlearn.service.rest.fastapi.clean_chunk_fastapi_service.CleanChunkModel"]], "faissindexbuilderservice (class in svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service)": [[9, "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.FaissIndexBuilderService"]], "inputrequest (class in svlearn.service.rest.fastapi.clean_chunk_fastapi_service)": [[9, "svlearn.service.rest.fastapi.clean_chunk_fastapi_service.InputRequest"]], "inputrequest (class in svlearn.service.rest.fastapi.sentence_embedding_fastapi_service)": [[9, "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.InputRequest"]], "sentenceencodermodel (class in svlearn.service.rest.fastapi.sentence_embedding_fastapi_service)": [[9, "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.SentenceEncoderModel"]], "vectorrequest (class in svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service)": [[9, "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.VectorRequest"]], "add_to_index() (in module svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service)": [[9, "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.add_to_index"]], "chunk() (in module svlearn.service.rest.fastapi.clean_chunk_fastapi_service)": [[9, "svlearn.service.rest.fastapi.clean_chunk_fastapi_service.chunk"]], "embedding() (in module svlearn.service.rest.fastapi.sentence_embedding_fastapi_service)": [[9, "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.embedding"]], "initialize_chunker() (svlearn.service.rest.fastapi.clean_chunk_fastapi_service.cleanchunkmodel method)": [[9, "svlearn.service.rest.fastapi.clean_chunk_fastapi_service.CleanChunkModel.initialize_chunker"]], "initialize_embedder() (svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.sentenceencodermodel method)": [[9, "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.SentenceEncoderModel.initialize_embedder"]], "initialize_index() (svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.faissindexbuilderservice method)": [[9, "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.FaissIndexBuilderService.initialize_index"]], "save_index() (svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.faissindexbuilderservice method)": [[9, "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.FaissIndexBuilderService.save_index"]], "sentences (svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.inputrequest attribute)": [[9, "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service.InputRequest.sentences"]], "svlearn.service.rest.fastapi": [[9, "module-svlearn.service.rest.fastapi"]], "svlearn.service.rest.fastapi.clean_chunk_fastapi_service": [[9, "module-svlearn.service.rest.fastapi.clean_chunk_fastapi_service"]], "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service": [[9, "module-svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service"]], "svlearn.service.rest.fastapi.sentence_embedding_fastapi_service": [[9, "module-svlearn.service.rest.fastapi.sentence_embedding_fastapi_service"]], "text (svlearn.service.rest.fastapi.clean_chunk_fastapi_service.inputrequest attribute)": [[9, "svlearn.service.rest.fastapi.clean_chunk_fastapi_service.InputRequest.text"]], "vectors (svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.vectorrequest attribute)": [[9, "svlearn.service.rest.fastapi.faiss_fastapi_index_builder_service.VectorRequest.vectors"]], "cleanchunkmodel (in module svlearn.service.rest.rayserve.clean_chunk_service)": [[10, "svlearn.service.rest.rayserve.clean_chunk_service.CleanChunkModel"]], "faissindexbuilderservice (in module svlearn.service.rest.rayserve.faiss_index_builder_service)": [[10, "svlearn.service.rest.rayserve.faiss_index_builder_service.FaissIndexBuilderService"]], "faisssearchservice (in module svlearn.service.rest.rayserve.faiss_search_service)": [[10, "svlearn.service.rest.rayserve.faiss_search_service.FaissSearchService"]], "hybridsearch (class in svlearn.service.rest.rayserve.search_service)": [[10, "svlearn.service.rest.rayserve.search_service.HybridSearch"]], "queryresultsrerankermodel (in module svlearn.service.rest.rayserve.query_results_reranking_service)": [[10, "svlearn.service.rest.rayserve.query_results_reranking_service.QueryResultsReRankerModel"]], "sentenceencodermodel (in module svlearn.service.rest.rayserve.sentence_embedding_service)": [[10, "svlearn.service.rest.rayserve.sentence_embedding_service.SentenceEncoderModel"]], "svlearn.service.rest.rayserve": [[10, "module-svlearn.service.rest.rayserve"]], "svlearn.service.rest.rayserve.clean_chunk_service": [[10, "module-svlearn.service.rest.rayserve.clean_chunk_service"]], "svlearn.service.rest.rayserve.faiss_index_builder_service": [[10, "module-svlearn.service.rest.rayserve.faiss_index_builder_service"]], "svlearn.service.rest.rayserve.faiss_search_service": [[10, "module-svlearn.service.rest.rayserve.faiss_search_service"]], "svlearn.service.rest.rayserve.query_results_reranking_service": [[10, "module-svlearn.service.rest.rayserve.query_results_reranking_service"]], "svlearn.service.rest.rayserve.search_service": [[10, "module-svlearn.service.rest.rayserve.search_service"]], "svlearn.service.rest.rayserve.sentence_embedding_service": [[10, "module-svlearn.service.rest.rayserve.sentence_embedding_service"]], "run() (in module svlearn.sql.connect)": [[11, "svlearn.sql.connect.run"]], "svlearn.sql": [[11, "module-svlearn.sql"]], "svlearn.sql.connect": [[11, "module-svlearn.sql.connect"]], "chunktext (class in svlearn.text.text_chunker)": [[12, "svlearn.text.text_chunker.ChunkText"]], "elasticsearchindex (class in svlearn.text.es_index_searcher)": [[12, "svlearn.text.es_index_searcher.ElasticSearchIndex"]], "faissindexer (class in svlearn.text.faiss_indexer)": [[12, "svlearn.text.faiss_indexer.FaissIndexer"]], "queryresultsreranker (class in svlearn.text.query_results_reranker)": [[12, "svlearn.text.query_results_reranker.QueryResultsReRanker"]], "sentenceencoder (class in svlearn.text.sentence_encoder)": [[12, "svlearn.text.sentence_encoder.SentenceEncoder"]], "textextraction (class in svlearn.text.text_extractor)": [[12, "svlearn.text.text_extractor.TextExtraction"]], "textextractionerror": [[12, "svlearn.text.text_extractor.TextExtractionError"]], "add() (svlearn.text.faiss_indexer.faissindexer method)": [[12, "svlearn.text.faiss_indexer.FaissIndexer.add"]], "cosine_similarity() (svlearn.text.text_chunker.chunktext static method)": [[12, "svlearn.text.text_chunker.ChunkText.cosine_similarity"]], "create_brute_force_index() (svlearn.text.faiss_indexer.faissindexer method)": [[12, "svlearn.text.faiss_indexer.FaissIndexer.create_brute_force_index"]], "create_chunks() (svlearn.text.text_chunker.chunktext method)": [[12, "svlearn.text.text_chunker.ChunkText.create_chunks"]], "create_hnsw_index() (svlearn.text.faiss_indexer.faissindexer method)": [[12, "svlearn.text.faiss_indexer.FaissIndexer.create_hnsw_index"]], "create_ivf_index() (svlearn.text.faiss_indexer.faissindexer method)": [[12, "svlearn.text.faiss_indexer.FaissIndexer.create_ivf_index"]], "create_list_of_chunks() (svlearn.text.text_chunker.chunktext method)": [[12, "svlearn.text.text_chunker.ChunkText.create_list_of_chunks"]], "document_type() (svlearn.text.text_extractor.textextraction static method)": [[12, "svlearn.text.text_extractor.TextExtraction.document_type"]], "encode() (svlearn.text.sentence_encoder.sentenceencoder method)": [[12, "svlearn.text.sentence_encoder.SentenceEncoder.encode"]], "load_index() (svlearn.text.faiss_indexer.faissindexer method)": [[12, "svlearn.text.faiss_indexer.FaissIndexer.load_index"]], "rerank() (svlearn.text.query_results_reranker.queryresultsreranker method)": [[12, "svlearn.text.query_results_reranker.QueryResultsReRanker.rerank"]], "save_index() (svlearn.text.faiss_indexer.faissindexer method)": [[12, "svlearn.text.faiss_indexer.FaissIndexer.save_index"]], "search() (svlearn.text.es_index_searcher.elasticsearchindex method)": [[12, "svlearn.text.es_index_searcher.ElasticSearchIndex.search"]], "size() (svlearn.text.faiss_indexer.faissindexer method)": [[12, "svlearn.text.faiss_indexer.FaissIndexer.size"]], "svlearn.text": [[12, "module-svlearn.text"]], "svlearn.text.es_index_searcher": [[12, "module-svlearn.text.es_index_searcher"]], "svlearn.text.faiss_indexer": [[12, "module-svlearn.text.faiss_indexer"]], "svlearn.text.indexer_poc": [[12, "module-svlearn.text.indexer_poc"]], "svlearn.text.query_results_reranker": [[12, "module-svlearn.text.query_results_reranker"]], "svlearn.text.sentence_encoder": [[12, "module-svlearn.text.sentence_encoder"]], "svlearn.text.text_chunker": [[12, "module-svlearn.text.text_chunker"]], "svlearn.text.text_extractor": [[12, "module-svlearn.text.text_extractor"]], "to_text() (svlearn.text.text_extractor.textextraction static method)": [[12, "svlearn.text.text_extractor.TextExtraction.to_text"]]}})