version: "3.8"

volumes:
  certs:
    driver: local
  esdata01:
    driver: local
  kibanadata:
    driver: local
  postgres_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  debezium_data:
    driver: local
  

networks:
 default:
   name: elastic
   external: false

services:
  postgres:
    image: postgres
    restart: always
    ports:
      - 5432:5432
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    command:
      - "postgres"
      - "-c"
      - "wal_level=logical"

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080
        
  tika:
    image: logicalspark/docker-tikaserver
    restart: always
    ports:
      - 9998:9998

        
  es01:
    # depends_on:
      # setup:
      #   condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    labels:
      co.elastic.logs/module: elasticsearch
    volumes:
      - certs:/usr/share/elasticsearch/config/certs
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - ${ES_PORT}:9200
    environment:
      - node.name=es01
      - http.host=0.0.0.0
      - transport.host=127.0.0.1
      - cluster.name=${CLUSTER_NAME}
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      # - xpack.security.enabled=true
      # - xpack.security.http.ssl.enabled=true
      # - xpack.security.http.ssl.key=certs/es01/es01.key
      # - xpack.security.http.ssl.certificate=certs/es01/es01.crt
      # - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      # - xpack.security.transport.ssl.enabled=true
      # - xpack.security.transport.ssl.key=certs/es01/es01.key
      # - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
      # - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      # - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    # healthcheck:
    #   test:
    #     [
    #       "CMD-SHELL",
    #       "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
    #     ]
    #   interval: 10s
    #   timeout: 10s
    #   retries: 120
        
  kibana:
     depends_on:
      - es01
      #  es01:
      #    condition: service_healthy
      #  setup:
      #    condition: service_completed_successfully
     image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
     labels:
       co.elastic.logs/module: kibana
     volumes:
       - certs:/usr/share/kibana/config/certs
       - kibanadata:/usr/share/kibana/data
     ports:
       - ${KIBANA_PORT}:5601
     environment:
       - SERVERNAME=kibana
       - ELASTICSEARCH_HOSTS=http://es01:9200
       - ELASTICSEARCH_USERNAME=kibana_system
       - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      #  - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
      #  - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      #  - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      #  - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
     mem_limit: ${KB_MEM_LIMIT}
     healthcheck:
       test:
         [
           "CMD-SHELL",
           "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
         ]
       interval: 10s
       timeout: 10s
       retries: 120

  zookeeper:
    image: quay.io/debezium/zookeeper:${DEBEZIUM_VERSION}
    ports:
     - 2181:2181
     - 2888:2888
     - 3888:3888
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.5.3
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9991
      
    ports:
      - 9092:9092
      - 29092:29092
    volumes:
      - kafka_data:/var/lib/kafka/data

  debezium:
    build:
      context: Docker/debezium
      args:
        DEBEZIUM_VERSION: ${DEBEZIUM_VERSION}
    volumes:
       - certs:/usr/share/debezium/config/certs
       - debezium_data:/usr/share/debezium/data
    ports:
     - 8083:8083
     - 5005:5005
    links:
     - kafka
     - postgres
     - es01
    environment:
     - BOOTSTRAP_SERVERS=kafka:9092
     - GROUP_ID=1
     - CONFIG_STORAGE_TOPIC=my_connect_configs
     - OFFSET_STORAGE_TOPIC=my_connect_offsets
     - STATUS_STORAGE_TOPIC=my_source_connect_statuses

    
  # postgres:
  #   image: quay.io/debezium/postgres:9.6
  #   ports:
  #    - 5432:5432
  #   environment:
  #    - POSTGRES_USER=${POSTGRES_USER}
  #    - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
  #    - POSTGRES_DB=${POSTGRES_DB}
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data

  # setup:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #   user: "0"
  #   command: >
  #     bash -c '
  #      if [ x${ELASTIC_PASSWORD} == x ]; then
  #        echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
  #        exit 1;
  #      elif [ x${KIBANA_PASSWORD} == x ]; then
  #        echo "Set the KIBANA_PASSWORD environment variable in the .env file";
  #        exit 1;
  #      fi;
  #      if [ ! -f config/certs/ca.zip ]; then
  #        echo "Creating CA";
  #        bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
  #        unzip config/certs/ca.zip -d config/certs;
  #      fi;
  #      if [ ! -f config/certs/certs.zip ]; then
  #        echo "Creating certs";
  #        echo -ne \
  #        "instances:\n"\
  #        "  - name: es01\n"\
  #        "    dns:\n"\
  #        "      - es01\n"\
  #        "      - localhost\n"\
  #        "    ip:\n"\
  #        "      - 127.0.0.1\n"\
  #        "  - name: kibana\n"\
  #        "    dns:\n"\
  #        "      - kibana\n"\
  #        "      - localhost\n"\
  #        "    ip:\n"\
  #        "      - 127.0.0.1\n"\
  #        > config/certs/instances.yml;
  #        bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
  #        unzip config/certs/certs.zip -d config/certs;
  #      fi;
  #      echo "Setting file permissions"
  #     #  chown -R root:root config/certs;
  #      chown -R 1000:1000 config/certs;
  #      chmod -R 755 config/certs;
  #      find . -type d -exec chmod 750 \{\} \;;
  #      find . -type f -exec chmod 640 \{\} \;;
  #      echo "Waiting for Elasticsearch availability";
  #      until curl -s --cacert config/certs/ca/ca.crt https://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
  #      echo "Setting kibana_system password";
  #      until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
  #      echo "All done!";
  #     '
  #   healthcheck:
  #     test: ["CMD-SHELL", "[ -f config/certs/es01/es01.crt ]"]
  #     interval: 1s
  #     timeout: 5s
  #     retries: 120
        
  # schema-registry:
  #   image: confluentinc/cp-schema-registry:5.5.3
  #   environment:
  #     - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
  #     - SCHEMA_REGISTRY_HOST_NAME=schema-registry
  #     - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8085,http://localhost:8085
      # Use PROTOBUF Converter
      # KAFKA_KEY_CONVERTER: io.confluent.connect.protobuf.ProtobufConverter
      # KAFKA_VALUE_CONVERTER: io.confluent.connect.protobuf.ProtobufConverter
      # KAFKA_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      # KAFKA_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
  #   ports:
  #     - 8085:8085
  #   depends_on: [zookeeper, kafka]


  # kafka:
  #   image: quay.io/debezium/kafka:${DEBEZIUM_VERSION}
  #   ports:
  #    - 9092:9092
  #    - 29092:29092
  #   links:
  #    - zookeeper
  #   environment:
  #     ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT